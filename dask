import tkinter as tk
from tkinter import filedialog, messagebox
import dask.dataframe as dd
import pandas as pd
import numpy as np
import os

def generate_column_names(num_columns):
    column_names = []
    for i in range(1, num_columns + 1):
        name = ""
        while i > 0:
            i, remainder = divmod(i - 1, 26)
            name = chr(65 + remainder) + name
        column_names.append(name)
    return column_names

def load_cdr_file(cdr_file_path):
    # Load CDR file as a Dask DataFrame with specified columns
    cdr_df = dd.read_csv(cdr_file_path, sep='|', encoding='ISO-8859-1', header=None)
    cdr_columns = generate_column_names(cdr_df.shape[1].compute())
    cdr_df.columns = cdr_columns
    cdr_df = cdr_df.set_index('J')  # Set index on 'J' column for faster merging
    return cdr_df

def process_single_feed_file(feed_file, cdr_df, output_file, close_value):
    # Load feed file as Dask DataFrame
    feed_df = dd.read_csv(feed_file, header=None, encoding='ISO-8859-1')
    feed_columns = generate_column_names(feed_df.shape[1].compute())
    feed_df.columns = feed_columns
    feed_df = feed_df.set_index('B')  # Set index on 'B' for merging

    # Merge with CDR file
    merged_df = feed_df.merge(cdr_df, left_index=True, right_index=True, how='left', suffixes=('_feed', '_cdr'))

    # Define numeric columns and downcast to save memory
    numeric_cols = ['M', 'Y', 'Z', 'AE']
    merged_df[numeric_cols] = merged_df[numeric_cols].apply(pd.to_numeric, errors='coerce', downcast='float')

    # Add calculated columns using Dask expressions
    merged_df['Units'] = -merged_df['M'].astype('float32')
    merged_df['EQD_SEC_FLAG'] = (merged_df['AM_feed'] == 'Y').astype('category')
    merged_df['MTM (Local CCY)'] = (merged_df['Y'] * merged_df['Z'] * merged_df['AE']).astype('float32')
    merged_df['Close'] = close_value

    # Collect output columns and write to disk
    output_df = merged_df.assign(
        Sent_Status="",
        Sent="",
        Error=dd.where(merged_df['A_cdr'].isna(), "Error", ""),
        Product="Equity Derivatives",
        Name=merged_df['Z'],
        LEI=merged_df['Y'],
        AppandShortName="GLOBALBOOK|" + merged_df.index.astype(str),
        CDR_Application="GLOBALBOOK",
        Short_name=merged_df.index,
        Entity=dd.where(merged_df['V'].notna(), merged_df['V'], merged_df['C']),
        Entity_ID=merged_df['F'],
        CDRID=merged_df['A_cdr'],
        EQD_Client=merged_df['C_feed'],
        Trade_ID=merged_df['F_feed'],
        RBC_ID="",
        RBC_Name="",
        RBC_shortname="",
        Fund=merged_df['C'],
        Trade_date=merged_df['O_feed'],
        Maturity_Date=merged_df['P_feed'],
        Sub_Product=merged_df['H_feed'],
        EQD_DF_FLAG="",
        EQD_SEC_FLAG=merged_df['EQD_SEC_FLAG'],
        Underlying="",
        Units=merged_df['Units'],
        Contract_size=merged_df['Z'],
        Call_put=merged_df['J_feed'],
        CCY=merged_df['K_feed'],
        Long_Short=merged_df['L_feed'],
        Adjustment="",
        Unit_Price_Local_CCY=merged_df['AJ_feed'],
        COB="",
        Close=merged_df['Close'],
        MTM_Local_CCY=merged_df['MTM (Local CCY)'],
        MTM_USD="",
        Strategy=merged_df['U_feed'],
        Load_Type=""
    )
    
    # Write output to CSV
    output_df.to_csv(output_file, single_file=True, mode='a', header=False, index=False)

class DataProcessorApp:
    def __init__(self, root):
        self.root = root
        self.root.title("Data Processor")
        
        # File paths
        self.feed_files = [None, None, None]
        self.cdr_file = None
        self.output_file = None
        
        # UI Setup
        tk.Label(root, text="Select Feed File 1").grid(row=0, column=0, padx=10, pady=5)
        self.feed1_btn = tk.Button(root, text="Browse", command=lambda: self.select_file(0))
        self.feed1_btn.grid(row=0, column=1, padx=10, pady=5)
        
        tk.Label(root, text="Select Feed File 2").grid(row=1, column=0, padx=10, pady=5)
        self.feed2_btn = tk.Button(root, text="Browse", command=lambda: self.select_file(1))
        self.feed2_btn.grid(row=1, column=1, padx=10, pady=5)
        
        tk.Label(root, text="Select Feed File 3").grid(row=2, column=0, padx=10, pady=5)
        self.feed3_btn = tk.Button(root, text="Browse", command=lambda: self.select_file(2))
        self.feed3_btn.grid(row=2, column=1, padx=10, pady=5)
        
        tk.Label(root, text="Select CDR File").grid(row=3, column=0, padx=10, pady=5)
        self.cdr_btn = tk.Button(root, text="Browse", command=self.select_cdr_file)
        self.cdr_btn.grid(row=3, column=1, padx=10, pady=5)
        
        tk.Label(root, text="Save Output As").grid(row=4, column=0, padx=10, pady=5)
        self.output_btn = tk.Button(root, text="Browse", command=self.select_output_file)
        self.output_btn.grid(row=4, column=1, padx=10, pady=5)
        
        # Process Button
        self.process_btn = tk.Button(root, text="Process Files", command=self.process_files)
        self.process_btn.grid(row=5, column=0, columnspan=2, pady=20)
    
    def select_file(self, idx):
        file_path = filedialog.askopenfilename(filetypes=[("CSV Files", "*.csv")])
        if file_path:
            self.feed_files[idx] = file_path
            tk.Label(self.root, text=os.path.basename(file_path)).grid(row=idx, column=2)
    
    def select_cdr_file(self):
        file_path = filedialog.askopenfilename(filetypes=[("PSV Files", "*.psv")])
        if file_path:
            self.cdr_file = file_path
            tk.Label(self.root, text=os.path.basename(file_path)).grid(row=3, column=2)
    
    def select_output_file(self):
        file_path = filedialog.asksaveasfilename(defaultextension=".csv", filetypes=[("CSV Files", "*.csv")])
        if file_path:
            self.output_file = file_path
            tk.Label(self.root, text=os.path.basename(file_path)).grid(row=4, column=2)

    def process_files(self):
        if not all(self.feed_files) or not self.cdr_file or not self.output_file:
            messagebox.showerror("Error", "Please select all feed files, CDR file, and output file.")
            return
        
        try:
            # Load CDR file as Dask DataFrame once and use it for all feed files
            cdr_df = load_cdr_file(self.cdr_file)

            # Process each feed file using Dask and save results incrementally
            for i, feed_file in enumerate(self.feed_files, start=1):
                process_single_feed_file(feed_file, cdr_df, self.output_file, i)
            
            messagebox.showinfo("Success", f"Combined data saved to {self.output_file}")
        
        except Exception as e:
            messagebox.showerror("Error", f"An error occurred: {e}")

# Run the application
if __name__ == '__main__':
    root = tk.Tk()
    app = DataProcessorApp(root)
    root.mainloop()
