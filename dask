import tkinter as tk
from tkinter import filedialog, messagebox
from tkinter import ttk  # For the progress bar
import threading
import pandas as pd
import numpy as np
import os
import gc
import multiprocessing as mp

def generate_column_names(num_columns):
    column_names = []
    for i in range(1, num_columns + 1):
        name = ""
        while i > 0:
            i, remainder = divmod(i - 1, 26)
            name = chr(65 + remainder) + name
        column_names.append(name)
    return column_names

def load_relevant_cdr_rows(cdr_file_path, required_values):
    # Read the first chunk to determine the actual column count in the CDR file
    first_chunk = pd.read_csv(cdr_file_path, sep='|', encoding='ISO-8859-1', header=None, nrows=1)
    actual_column_count = first_chunk.shape[1]
    cdr_columns = generate_column_names(actual_column_count)

    # Load only the necessary rows from the CDR file in chunks, using the actual column count
    cdr_filtered_chunks = []
    cdr_iterator = pd.read_csv(cdr_file_path, sep='|', encoding='ISO-8859-1', header=None, chunksize=1000, names=cdr_columns)

    for chunk in cdr_iterator:
        filtered_chunk = chunk[chunk['J'].isin(required_values)]
        
        # Add only non-empty, non-all-NA filtered chunks
        if not filtered_chunk.empty and not filtered_chunk.isna().all(axis=None):
            cdr_filtered_chunks.append(filtered_chunk)

    # Concatenate all filtered chunks into a single DataFrame, only if non-empty chunks are present
    if cdr_filtered_chunks:
        cdr_df = pd.concat(cdr_filtered_chunks).set_index('J')
    else:
        cdr_df = pd.DataFrame(columns=cdr_columns).set_index('J')  # Return empty DataFrame with correct columns if no rows match

    return cdr_df

def process_single_feed_file(feed_file, cdr_df, output_file, close_value, progress_queue, cancel_flag):
    chunk_size = 1000
    first_chunk = True

    for feed_chunk in pd.read_csv(feed_file, header=None, encoding='ISO-8859-1', chunksize=chunk_size):
        if cancel_flag.value == 1:
            return  # Exit if cancel flag is set

        feed_columns = generate_column_names(feed_chunk.shape[1])
        feed_chunk.columns = feed_columns
        feed_chunk.set_index('B', inplace=True)  # Assuming 'B' is the key for merging

        merged_df = feed_chunk.join(cdr_df, how='left', rsuffix='_cdr')
        numeric_cols = ['M', 'Y', 'Z', 'AE']
        merged_df[numeric_cols] = merged_df[numeric_cols].apply(pd.to_numeric, errors='coerce', downcast='float')

        merged_df['Product'] = 'Equity Derivatives'
        merged_df['Product'] = merged_df['Product'].astype('category')
        merged_df['EQD_SEC_FLAG'] = merged_df['AM'] == 'Y'
        merged_df['EQD_SEC_FLAG'] = merged_df['EQD_SEC_FLAG'].astype('category')
        
        merged_df['Units'] = -np.asarray(merged_df['M'], dtype=np.float32)
        merged_df['MTM (Local CCY)'] = (
            np.asarray(merged_df['Y'], dtype=np.float32) * 
            np.asarray(merged_df['Z'], dtype=np.float32) * 
            np.asarray(merged_df['AE'], dtype=np.float32)
        )
        merged_df['Close'] = close_value

        output_df = merged_df.assign(
            Sent_Status="",
            Sent="",
            Error=np.where(merged_df['A_cdr'].isna(), "Error", ""),
            Product=merged_df['Product'],
            Name=merged_df['Z'],
            LEI=merged_df['Y'],
            AppandShortName="GLOBALBOOK|" + merged_df.index.astype(str),
            CDR_Application="GLOBALBOOK",
            Short_name=merged_df.index,
            Entity=np.where(merged_df['V'].notna(), merged_df['V'], merged_df['C']),
            Entity_ID=merged_df['F'],
            CDRID=merged_df['A_cdr'],
            EQD_Client=merged_df['C'],
            Trade_ID=merged_df['F'],
            RBC_ID="",
            RBC_Name="",
            RBC_shortname="",
            Fund=merged_df['C'],
            Trade_date=merged_df['O'],
            Maturity_Date=merged_df['P'],
            Sub_Product=merged_df['H'],
            EQD_DF_FLAG="",
            EQD_SEC_FLAG=merged_df['EQD_SEC_FLAG'],
            Underlying="",
            Units=merged_df['Units'],
            Contract_size=merged_df['Z'],
            Call_put=merged_df['J'],
            CCY=merged_df['K'],
            Long_Short=merged_df['L'],
            Adjustment="",
            Unit_Price_Local_CCY=merged_df['AJ'],
            COB="",
            Close=merged_df['Close'],
            MTM_Local_CCY=merged_df['MTM (Local CCY)'],
            MTM_USD="",
            Strategy=merged_df['U'],
            Load_Type=""
        )

        output_df.to_csv(output_file, mode='a', index=False, header=first_chunk)
        first_chunk = False

        del feed_chunk, merged_df, output_df
        gc.collect()

    progress_queue.put(1)  # Signal completion for this file

class DataProcessorApp:
    def __init__(self, root):
        self.root = root
        self.root.title("Data Processor")
        
        self.feed_files = [None, None, None]
        self.cdr_file = None
        self.output_file = None
        self.process_pool = None

        tk.Label(root, text="Select Feed File 1").grid(row=0, column=0, padx=10, pady=5)
        self.feed1_btn = tk.Button(root, text="Browse", command=lambda: self.select_file(0))
        self.feed1_btn.grid(row=0, column=1, padx=10, pady=5)
        
        tk.Label(root, text="Select Feed File 2").grid(row=1, column=0, padx=10, pady=5)
        self.feed2_btn = tk.Button(root, text="Browse", command=lambda: self.select_file(1))
        self.feed2_btn.grid(row=1, column=1, padx=10, pady=5)
        
        tk.Label(root, text="Select Feed File 3").grid(row=2, column=0, padx=10, pady=5)
        self.feed3_btn = tk.Button(root, text="Browse", command=lambda: self.select_file(2))
        self.feed3_btn.grid(row=2, column=1, padx=10, pady=5)
        
        tk.Label(root, text="Select CDR File").grid(row=3, column=0, padx=10, pady=5)
        self.cdr_btn = tk.Button(root, text="Browse", command=self.select_cdr_file)
        self.cdr_btn.grid(row=3, column=1, padx=10, pady=5)
        
        tk.Label(root, text="Save Output As").grid(row=4, column=0, padx=10, pady=5)
        self.output_btn = tk.Button(root, text="Browse", command=self.select_output_file)
        self.output_btn.grid(row=4, column=1, padx=10, pady=5)
        
        self.progress = ttk.Progressbar(root, orient='horizontal', length=300, mode='determinate')
        self.progress.grid(row=6, column=0, columnspan=2, pady=10)

        self.process_btn = tk.Button(root, text="Process Files", command=self.start_processing)
        self.process_btn.grid(row=5, column=0, pady=20)

        self.cancel_btn = tk.Button(root, text="Cancel", command=self.cancel_processing)
        self.cancel_btn.grid(row=5, column=1, pady=20)
    
    def select_file(self, idx):
        file_path = filedialog.askopenfilename(filetypes=[("CSV Files", "*.csv")])
        if file_path:
            self.feed_files[idx] = file_path
            tk.Label(self.root, text=os.path.basename(file_path)).grid(row=idx, column=2)
    
    def select_cdr_file(self):
        file_path = filedialog.askopenfilename(filetypes=[("PSV Files", "*.psv")])
        if file_path:
            self.cdr_file = file_path
            tk.Label(self.root, text=os.path.basename(file_path)).grid(row=3, column=2)
    
    def select_output_file(self):
        file_path = filedialog.asksaveasfilename(defaultextension=".csv", filetypes=[("CSV Files", "*.csv")])
        if file_path:
            self.output_file = file_path
            tk.Label(self.root, text=os.path.basename(file_path)).grid(row=4, column=2)

    def start_processing(self):
        self.process_btn.config(state="disabled", text="Processing...")
        self.cancel_flag = mp.Value('i', 0)
        self.progress_queue = mp.Queue()
        self.progress['value'] = 0
        threading.Thread(target=self.process_files).start()

    def cancel_processing(self):
        self.cancel_flag.value = 1
        if self.process_pool:
            self.process_pool.terminate()
        self.process_btn.config(state="normal", text="Process Files")
        self.progress.stop()

    def process_files(self):
        if not all(self.feed_files) or not self.cdr_file or not self.output_file:
            messagebox.showerror("Error", "Please select all feed files, CDR file, and output file.")
            self.process_btn.config(state="normal", text="Process Files")
            return
        
        try:
            # Corrected set comprehension to collect unique short_name values without error
            required_values = {val for feed_file in self.feed_files for chunk in pd.read_csv(feed_file, header=None, usecols=[1], chunksize=1000, encoding='ISO-8859-1') for val in chunk[1].unique()}
            
            # Load only relevant rows from CDR file
            cdr_df = load_relevant_cdr_rows(self.cdr_file, required_values)
            total_files = len(self.feed_files)

            with mp.Pool(processes=mp.cpu_count()) as pool:
                self.process_pool = pool
                tasks = [
                    pool.apply_async(process_single_feed_file, args=(
                        feed_file, cdr_df, self.output_file, i, self.progress_queue, self.cancel_flag
                    ))
                    for i, feed_file in enumerate(self.feed_files, start=1)
                ]

                completed = 0
                while completed < total_files:
                    if self.cancel_flag.value == 1:
                        break
                    self.progress_queue.get()
                    completed += 1
                    self.progress['value'] = (completed / total_files) * 100
                    self.root.update_idletasks()

                pool.close()
                pool.join()
                
            if self.cancel_flag.value == 0:
                messagebox.showinfo("Success", f"Combined data saved to {self.output_file}")
        
        except Exception as e:
            messagebox.showerror("Error", f"An error occurred: {e}")
        
        finally:
            self.process_btn.config(state="normal", text="Process Files")
            self.progress['value'] = 0

# Run the application
if __name__ == '__main__':
    root = tk.Tk()
    app = DataProcessorApp(root)
    root.mainloop()
